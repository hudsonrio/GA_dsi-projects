{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "\n",
    "deaths_simple = pd.read_csv('/Users/HudsonCavanagh/Dropbox/Capstone/cdc_data/deaths_simple.csv', delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "#Quick Explore\n",
    "\n",
    "pov_county_year_03_14['year'].value_counts()\n",
    "pov_county_year_03_14.describe()\n",
    "deaths_pop.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "#Concat\n",
    "\n",
    "pop_03_14 = pd.concat([pop_03, pop_04, pop_05, pop_06, pop_07, pop_08, pop_09, pop_10_14], axis=0) #this works 1) need to make floats 2) need more data\n",
    "\n",
    "\n",
    "\n",
    "#Merge\n",
    "\n",
    "deaths_pop = pd.merge(deaths_pop, pop_03_14, how='left', left_on=['year', 'county_code'], right_on=['year', 'county_code'])\n",
    "deaths_pop.reset_index(inplace=1)\n",
    "\n",
    "\n",
    "#Groupby\n",
    "\n",
    "deaths_pop = cdc_03_14.groupby(by=['year', 'county_code']).sum()\n",
    "\n",
    "\n",
    "\n",
    "#Pivot Table\n",
    "state_change = pd.pivot_table(deaths_pop, values=['drug_death_rate_100k'], index=['state', 'year'], aggfunc='mean')\n",
    "\n",
    "#Dropping Values\n",
    "\n",
    "#Rows\n",
    "deaths_pop.drop(886, inplace=1)\n",
    "\n",
    "deaths_pop.dropna(axis=0, subset=['working_pop', 'employed_pop', 'deaths_raw', 'population_est'], inplace=1)\n",
    "\n",
    "\n",
    "#Cleaner Functions\n",
    "\n",
    "def yearify(year):\n",
    "    year = float(year)\n",
    "    try:\n",
    "        return int(year)\n",
    "    except:  \n",
    "        return year\n",
    "    \n",
    "def interator(example):\n",
    "    try:\n",
    "        example = str(example).split('.')[0]\n",
    "        return int(example)\n",
    "    except:\n",
    "        return example\n",
    "    \n",
    "def death_clean(death):\n",
    "    try:\n",
    "        return float(death)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "\n",
    "#Feature Scaling\n",
    "\n",
    "X = StandardScaler().fit_transform(features)\n",
    "X = pd.DataFrame(X, columns=features.columns)\n",
    "\n",
    "#PCA for later plots & model testing\n",
    "\n",
    "pca_2 = PCA(n_components=2)\n",
    "pca_3 = PCA(n_components=3)\n",
    "pca_4 = PCA(n_components=4)\n",
    "xPC_2 = pca_2.fit_transform(X)\n",
    "xPC_3 = pca_3.fit_transform(X)\n",
    "xPC_4 = pca_4.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "#Train test split & Cross Validation\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor\n",
    "import seaborn as sns\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf_cv = RandomForestRegressor()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=50)\n",
    "rf.fit(X_train, y_train)\n",
    "ypred_rf = rf.predict(X_test)\n",
    "s_rf_cv = cross_val_score(rf_cv, X, y, cv=stratk, n_jobs=-1)\n",
    "    \n",
    "s_rf_cv.mean()\n",
    "\n",
    "\n",
    "\n",
    "#Basic GB Regression Implementation\n",
    "\n",
    "gb_delta_14_mod = GradientBoostingRegressor(n_estimators=10000, learning_rate=.02)\n",
    "\n",
    "\n",
    "gb_delta_14_mod.fit(X_03_13_mod, y_delta_grow_03_13) # works\n",
    "gb_delta_14_ypred_mod = gb_delta_14.predict(X_14_mod)\n",
    "\n",
    "#XG Boost\n",
    "\n",
    "import xgboost\n",
    "\n",
    "xg_class_model_cv = xgboost.XGBClassifier()\n",
    "\n",
    "s_xg_cv = cross_val_score(xg_class_model_cv, X, y_bin, cv=stratk, n_jobs=-1)\n",
    "\n",
    "s_xg_cv.mean()\n",
    "\n",
    "\n",
    "# fit model no training data\n",
    "xg_model = xgboost.XGBRegressor()\n",
    "xg_model_cv = xgboost.XGBRegressor()\n",
    "xg_model.fit(X_train, y_train)\n",
    "\n",
    "s_xg_cv = cross_val_score(xg_model_cv, X, y, cv=stratk, n_jobs=-1)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred_xg = xg_model.predict(X_test)\n",
    "s_xg_cv.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Basic GB Classification Implementation\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "y_bin_03_13 = y_03_13.apply(lambda x: 1 if x > median_drug_rate else 0)\n",
    "y_bin_14_obs = y_14['drug_death_rate_100k'].apply(lambda x: 1 if x > median_drug_rate else 0)\n",
    "\n",
    "\n",
    "xg_class_model_14 = xgboost.XGBClassifier()\n",
    "xg_class_model_14.fit(X_03_13, y_bin_03_13)\n",
    "y_class_14 = xg_class_model_14.predict(X_14)\n",
    "\n",
    "xg_14_cm = confusion_matrix(y_bin_14_obs, y_class_14, labels=xg_class_model_14.classes_)\n",
    "\n",
    "\n",
    "\n",
    "#Eval Metrics - \n",
    "\n",
    "\n",
    "#Regression\n",
    "\n",
    "r2_score(y_delta_grow_14, gb_delta_14_ypred_mod)\n",
    "\n",
    "\n",
    "sns.regplot(ypred_gbtree, y_test, color=\"orange\")\n",
    "plt.xlabel('Predicted Mortality Rate (Gradient Boosted)')\n",
    "plt.ylabel('Actual Mortality Rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Classification\n",
    "\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', labels=['Positive','Negative'], cmap=plt.cm.Blues):\n",
    "   \n",
    "   plt.figure(figsize=(7,7))\n",
    "   plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "   \n",
    "   tick_marks = np.arange(2)\n",
    "   plt.xticks(tick_marks, labels)\n",
    "   plt.yticks(tick_marks, labels)\n",
    "       \n",
    "   plt.title(title)\n",
    "   plt.ylabel('True label')\n",
    "   plt.xlabel('Predicted label')\n",
    "   plt.colorbar()\n",
    "   plt.tight_layout()\n",
    "   \n",
    "   width, height = cm.shape\n",
    "   \n",
    "   for x in xrange(width):\n",
    "       for y in xrange(height):\n",
    "           plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "                       horizontalalignment='center',\n",
    "                       verticalalignment='center',\n",
    "                       color = 'white',\n",
    "                       fontsize=18).set_path_effects([path_effects.Stroke(linewidth=1, foreground='black'),\n",
    "                                                      path_effects.Normal()]) #The last line here adds a text outline\n",
    "        \n",
    "plot_confusion_matrix(xg_14_cm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Gradient Boost with Grid Search\n",
    "\n",
    "this code work, yielded:\n",
    "{'max_depth': 2,\n",
    " 'max_features': 'auto',\n",
    " 'min_samples_leaf': 5,\n",
    " 'min_samples_split': 5}    \n",
    "\n",
    "\n",
    "max_feature_list = ['auto']\n",
    "param_test = {'max_depth':[2,5], 'max_features':max_feature_list, 'min_samples_split':[2,5], 'min_samples_leaf':[2,5]}\n",
    "\n",
    "gb_delta_14_reg = GradientBoostingRegressor(n_estimators=100, learning_rate=.1)\n",
    "gb_delta_14_class = GradientBoostingClassifier(n_estimators=10000, learning_rate=.02)\n",
    "\n",
    "gs_delta_14_reg = GridSearchCV(gb_delta_14_reg, param_test, verbose=False, cv=15)\n",
    "gs_delta_14_reg.fit(X_03_13_mod, y_delta_grow_03_13)\n",
    "y_delta_14_gs_preds = gs_delta_14_reg.predict(X_14_mod)\n",
    "\n",
    "\n",
    "gs_delta_14_reg.best_params_\n",
    "\n",
    "\n",
    "#Feature Importance\n",
    "\n",
    "rel_feature_import = sorted(zip(rf.feature_importances_, features.columns), reverse=True)\n",
    "rel_feature_import = pd.DataFrame(rel_feature_import)\n",
    "rel_feature_import\n",
    "\n",
    "\n",
    "#Unsupervised Clustering\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "db1 = DBSCAN(eps = 4, min_samples = 15).fit(X)  \n",
    "db1labels = db1.labels_  \n",
    "core_samples = db1.core_sample_indices_\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\" \n",
    "      % silhouette_score(X, db1labels), len(set(db1labels)), db1labels.mean())\n",
    "\n",
    "\n",
    "\n",
    "#PCA 2-D Graphing\n",
    "\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "xPC_2 = pd.DataFrame(xPC_2, columns=['pc1', 'pc2'])\n",
    "xPC_2.head()\n",
    "\n",
    "graph = xPC_2.plot(kind='scatter', x='pc1', y='pc2', figsize=(16,8))\n",
    "\n",
    "for i, county in enumerate(deaths_pop['county_name']):\n",
    "    graph.annotate(county, (xPC_2.iloc[i,0], xPC_2.iloc[i,1]))\n",
    "    \n",
    "    \n",
    "#t-SNE 2-D Graphing\n",
    "\n",
    "import datetime\n",
    "from tsne import bh_sne\n",
    "# tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "# t0 = datetime.time()\n",
    "# X_tsne = tsne.fit_transform(features)\n",
    "\n",
    "\n",
    "X_2d = bh_sne(X)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.scatter(X_2d[:,0],X_2d[:,1])\n",
    "plt.title('t-SNE')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 New",
   "language": "python",
   "name": "stats_mods_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
