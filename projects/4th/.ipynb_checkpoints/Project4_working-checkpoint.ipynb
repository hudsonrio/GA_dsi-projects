{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary predictor with Logistic Regression.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use Logistic Regression.\n",
    "\n",
    "- Question: Why would we want this to be a classification problem?\n",
    "- Answer: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9732c901-ae26-4160-8376-42e22dd327df"
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e915023e-6b0d-4982-af2a-b1e0355f4927"
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2c6752c4-7704-4c94-8bc0-6f13d2d0d570"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "bb0b866a-26a7-45e9-8084-5a0f90eb4b3e"
   },
   "source": [
    "Let's look at one result more closely. A single `result` looks like\n",
    "\n",
    "```\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=2480d203f7e97210&amp;jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```\n",
    "\n",
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a `nobr` element inside of a `td` element with `class='snip`.\n",
    "- The title of a job is in a link with class set to `jobtitle` and a `data-tn-element=\"jobTitle`.  \n",
    "- The location is set in a `span` with `class='location'`. \n",
    "- The company is set in a `span` with `class='company'`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "f1eddb90-4ba8-483c-a229-77e93aa53119"
   },
   "source": [
    "### Write 4 functions to extract each item: location, company, job, and salary.\n",
    "\n",
    "example: \n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "\n",
    "- Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    "- Test the functions on the results above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a1af53c9-9090-494f-b82e-cadb60a54909"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34070e89-9521-4b45-90c8-57a6599aac68"
   },
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the `l=New+York` and the `start=10`. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "e8beed7c-3e42-40c0-810f-5f67f8f885a0"
   },
   "source": [
    "#### Complete the following code to collect results from multiple cities and starting points. \n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a9aa87ec-3575-4a01-a986-eb684f2c47d0"
   },
   "outputs": [],
   "source": [
    "YOUR_CITY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "04b0f9af-540e-402f-8292-81748707c676"
   },
   "outputs": [],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 100\n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', YOUR_CITY]):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        # Grab the results from the request (as above)\n",
    "        # Append to the full set of results\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "1. Some of the salaries are not yearly but hourly, these will be useful to us for now\n",
    "2. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Filter out the salaries that are not yearly (filter those that refer to hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/HudsonCavanagh/DSI-NYC-1/projects/01-projects-weekly/project-04/starter-code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "sample_indeed = pd.read_csv('/Users/HudsonCavanagh/dsi-projects/projects/4th/indeed_ds_data6_first.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>title</th>\n",
       "      <th>hourly_salary</th>\n",
       "      <th>monthly_salary</th>\n",
       "      <th>annual_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>How a Data Scientist works. As a Data Scientis...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>Work closely with stakeholders on the data dem...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MaxPoint</td>\n",
       "      <td>Senior Data Scientist. Mentor other data scien...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>IBM</td>\n",
       "      <td>\\nCreating and maintaining machine learning mo...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blue Spark - Watson Cognitive Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>IBM</td>\n",
       "      <td>\\nAutomatically find and interpret data rich s...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Engineer / Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Samsung Austin Semiconductor, LLC</td>\n",
       "      <td>\\nData Engineer position in the Data Science g...</td>\n",
       "      <td>Austin, TX 78754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>\\nData Engineer position in the Data Science g...</td>\n",
       "      <td>Austin, TX 78754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Amazon Corporate LLC</td>\n",
       "      <td>\\nStrong grasp of data structures and algorith...</td>\n",
       "      <td>Austin, TX 78728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Dell</td>\n",
       "      <td>\\nData Scientist - Round Rock, TX. Strong fami...</td>\n",
       "      <td>Round Rock, TX 78664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist Round Rock TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>HomeAway</td>\n",
       "      <td>\\nIf so, then HomeAway has a Data Scientist ro...</td>\n",
       "      <td>Austin, TX 78704 (South Lamar-South Congress a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Research Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Intersys:Big Data And Application Development</td>\n",
       "      <td>\\nJr Data Scientist*. Jr Data Scientist Job De...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jr Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>21CT</td>\n",
       "      <td>\\nDeep learning, data mining, data fusion, mac...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Gallup</td>\n",
       "      <td>\\nGallup data scientists help clients effectiv...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist – Predictive Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Sense Corp</td>\n",
       "      <td>Data analyst/data scientist role:. Perform dat...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Gallup</td>\n",
       "      <td>Gallup data scientists help clients effectivel...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist – Predictive Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Sense Corp</td>\n",
       "      <td>Data analyst/data scientist role:. Perform dat...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>MaxPoint</td>\n",
       "      <td>Senior Data Scientist. Mentor other data scien...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Atlantic Engineering Services</td>\n",
       "      <td>\\nData entry of mathematical analysis for wire...</td>\n",
       "      <td>Austin, TX 78704 (South Lamar-South Congress a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Make Ready Engineering Specialist (data analys...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Express Scripts</td>\n",
       "      <td>\\nMapping qualitative data to quantitative dat...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Quantitative UX Researcher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Precision For Value</td>\n",
       "      <td>\\nAdministrative hospital data, Electronic hea...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Research Scientist, Advanced Modeling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                            company  \\\n",
       "0            0                                             Indeed   \n",
       "1            1                                             Indeed   \n",
       "2            2                                           MaxPoint   \n",
       "3            3                                                IBM   \n",
       "4            4                                                IBM   \n",
       "5            5                  Samsung Austin Semiconductor, LLC   \n",
       "6            6                                            Samsung   \n",
       "7            7                               Amazon Corporate LLC   \n",
       "8            8                                               Dell   \n",
       "9            9                                           HomeAway   \n",
       "10          10      Intersys:Big Data And Application Development   \n",
       "11          11                                               21CT   \n",
       "12          12                                             Gallup   \n",
       "13          13                                         Sense Corp   \n",
       "14          14                                             Gallup   \n",
       "15          15                                         Sense Corp   \n",
       "16          16                                           MaxPoint   \n",
       "17          17                      Atlantic Engineering Services   \n",
       "18          18                                    Express Scripts   \n",
       "19          19                                Precision For Value   \n",
       "\n",
       "                                          description  \\\n",
       "0   How a Data Scientist works. As a Data Scientis...   \n",
       "1   Work closely with stakeholders on the data dem...   \n",
       "2   Senior Data Scientist. Mentor other data scien...   \n",
       "3   \\nCreating and maintaining machine learning mo...   \n",
       "4   \\nAutomatically find and interpret data rich s...   \n",
       "5   \\nData Engineer position in the Data Science g...   \n",
       "6   \\nData Engineer position in the Data Science g...   \n",
       "7   \\nStrong grasp of data structures and algorith...   \n",
       "8   \\nData Scientist - Round Rock, TX. Strong fami...   \n",
       "9   \\nIf so, then HomeAway has a Data Scientist ro...   \n",
       "10  \\nJr Data Scientist*. Jr Data Scientist Job De...   \n",
       "11  \\nDeep learning, data mining, data fusion, mac...   \n",
       "12  \\nGallup data scientists help clients effectiv...   \n",
       "13  Data analyst/data scientist role:. Perform dat...   \n",
       "14  Gallup data scientists help clients effectivel...   \n",
       "15  Data analyst/data scientist role:. Perform dat...   \n",
       "16  Senior Data Scientist. Mentor other data scien...   \n",
       "17  \\nData entry of mathematical analysis for wire...   \n",
       "18  \\nMapping qualitative data to quantitative dat...   \n",
       "19  \\nAdministrative hospital data, Electronic hea...   \n",
       "\n",
       "                                             location  salary  \\\n",
       "0                                          Austin, TX     NaN   \n",
       "1                                          Austin, TX     NaN   \n",
       "2                                          Austin, TX     NaN   \n",
       "3                                          Austin, TX     NaN   \n",
       "4                                          Austin, TX     NaN   \n",
       "5                                    Austin, TX 78754     NaN   \n",
       "6                                    Austin, TX 78754     NaN   \n",
       "7                                    Austin, TX 78728     NaN   \n",
       "8                                Round Rock, TX 78664     NaN   \n",
       "9   Austin, TX 78704 (South Lamar-South Congress a...     NaN   \n",
       "10                                         Austin, TX     NaN   \n",
       "11                                         Austin, TX     NaN   \n",
       "12                                         Austin, TX     NaN   \n",
       "13                                         Austin, TX     NaN   \n",
       "14                                         Austin, TX     NaN   \n",
       "15                                         Austin, TX     NaN   \n",
       "16                                         Austin, TX     NaN   \n",
       "17  Austin, TX 78704 (South Lamar-South Congress a...     NaN   \n",
       "18                                         Austin, TX     NaN   \n",
       "19                                         Austin, TX     NaN   \n",
       "\n",
       "                                                title  hourly_salary  \\\n",
       "0                                      Data Scientist            NaN   \n",
       "1                                       Data Engineer            NaN   \n",
       "2                               Senior Data Scientist            NaN   \n",
       "3     Blue Spark - Watson Cognitive Software Engineer            NaN   \n",
       "4                      Data Engineer / Data Scientist            NaN   \n",
       "5                                      Data Scientist            NaN   \n",
       "6                                      Data Scientist            NaN   \n",
       "7                          Machine Learning Scientist            NaN   \n",
       "8                        Data Scientist Round Rock TX            NaN   \n",
       "9                             Research Data Scientist            NaN   \n",
       "10                                  Jr Data Scientist            NaN   \n",
       "11                                 Research Scientist            NaN   \n",
       "12              Data Scientist – Predictive Analytics            NaN   \n",
       "13                                     Data Scientist            NaN   \n",
       "14              Data Scientist – Predictive Analytics            NaN   \n",
       "15                                     Data Scientist            NaN   \n",
       "16                              Senior Data Scientist            NaN   \n",
       "17  Make Ready Engineering Specialist (data analys...            NaN   \n",
       "18                  Senior Quantitative UX Researcher            NaN   \n",
       "19              Research Scientist, Advanced Modeling            NaN   \n",
       "\n",
       "    monthly_salary  annual_salary  \n",
       "0              NaN            NaN  \n",
       "1              NaN            NaN  \n",
       "2              NaN            NaN  \n",
       "3              NaN            NaN  \n",
       "4              NaN            NaN  \n",
       "5              NaN            NaN  \n",
       "6              NaN            NaN  \n",
       "7              NaN            NaN  \n",
       "8              NaN            NaN  \n",
       "9              NaN            NaN  \n",
       "10             NaN            NaN  \n",
       "11             NaN            NaN  \n",
       "12             NaN            NaN  \n",
       "13             NaN            NaN  \n",
       "14             NaN            NaN  \n",
       "15             NaN            NaN  \n",
       "16             NaN            NaN  \n",
       "17             NaN            NaN  \n",
       "18             NaN            NaN  \n",
       "19             NaN            NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_indeed.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "annual_avg_sal = sample_indeed['annual_salary'].mean()\n",
    "#need assumption for hours of work annually...\n",
    "sample_indeed['salary'] = (sample_indeed['monthly_salary']*12)\n",
    "sample_indeed['salary'] = (sample_indeed['hourly_salary']*12*5*9)#12 month, 5 days/ week, 9 hours/day\n",
    "#sample_indeed['salary'] = (sample_indeed['annual_salary'] -- should be accounted for already\n",
    "avg_sal = sample_indeed['salary'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "#50% -- because we're using the average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts for features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Logistic Regression model to predict High/Low salary using statsmodel. Start by ONLY using the location as a feature. Display the coefficients and write a short summary of what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "import statsmodel\n",
    "\n",
    "X_basic = indeed_sample['location']\n",
    "Y_basic = sample_indeed['salary'].values\n",
    "\n",
    "\n",
    "X_trainb, X_testb, y_trainb, y_testb = train_test_split(X_basic, y_basic, test_size=0.33, random_state=50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_basic = LogisticRegression(C=1.5, penalty='l1', solver='liblinear') #can i take away penalty? make sure this is statsmodels\n",
    "lr_basic_model = lr_basic.fit(X_trainb, y_trainb)\n",
    "lr_basic_ypred = lr_basic_model.predict(X_testb)\n",
    "\n",
    "#dmmatrices is another technique that does both these things in 1\n",
    "\n",
    "burg_drug = pd.DataFrame(X1, columns=X1.design_info.column_names)\n",
    "burg_drug['Target'] \n",
    "burg_drug\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.33, random_state=77)\n",
    "\n",
    "lr_basic_cm = confusion_matrix(y_testb, lr_basic_ypred, labels=lr_basic.classes_)\n",
    "lr_basic_cm_df = pd.DataFrame(lr_basic_cm, columns=lr_basic.classes_, index=lr_basic.classes_.classes_) #lr_l1_SF is instance of model\n",
    "lr_basic_cm_df\n",
    "\n",
    "#from http://localhost:8888/notebooks/dsi-projects/week04/w4d4_advanced_model_tuning_gridsearch_worksheet.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title \n",
    "- or whether 'Manager' is in the title. \n",
    "- Then build a new Logistic Regression model with these features. Do they add any value? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ideas for features:\n",
    "####location\n",
    "-proxy for region\n",
    "-find cost of living by city (estimate)\n",
    "-major hub proxy (SF, NYC)\n",
    "-fourtune 100?\n",
    "\n",
    "####role title (if the following words in description)\n",
    "-senior (or sr. or sr)\n",
    "-junior (or jr. or jr)\n",
    "-python\n",
    "-r\n",
    "-tableau\n",
    "-Machine Learning\n",
    "-Software Develop\n",
    "-volume\n",
    "-big/ large/ \n",
    "-advanced\n",
    "-predictive\n",
    "-lead\n",
    "-principle\n",
    "-analytic\n",
    "-insight\n",
    "-SQL\n",
    "-finance/ financial\n",
    "-visualization\n",
    "-model\n",
    "-optimize\n",
    "-specialist\n",
    "-mining/ munging/ cleaning\n",
    "-scraping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = patsy.dmatrix('~ C(hour) + C(DayOfWeek) + C(PdDistrict)', sf_crime_small) #dmatrix uses formula to output independ vars\n",
    "y1 = sample_indeed['salary'].values #set target\n",
    "\n",
    "\n",
    "lr_l1_SF = LogisticRegression(C=1.5, penalty='l1', solver='liblinear')\n",
    "lr_l1_model1 = lr_l1_SF.fit(X_train1, y_train1)\n",
    "lr_l1_ypred1 = lr_l1_model1.predict(X_test1)\n",
    "\n",
    "\n",
    "lr_l1_cm_1 = confusion_matrix(y_test1, lr_l1_ypred1, labels=lr_l1_SF.classes_)\n",
    "lr_l1_cm_1 = pd.DataFrame(lr_l1_cm_1, columns=lr_l1_SF.classes_, index=lr_l1_SF.classes_) #lr_l1_SF is instance of model\n",
    "lr_l1_cm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adapt this!!!!!!\n",
    "lr_l2_SF = LogisticRegression(C=1.5, penalty='l2', solver='liblinear')\n",
    "lr_l2_model1 = lr_l2_SF.fit(X_train1, y_train1)\n",
    "lr_l2_ypred1 = lr_l2_model1.predict(X_test1)\n",
    "lr_l2_cm_2 = confusion_matrix(y_test1, lr_l2_ypred1, labels=lr_l2_SF.classes_)\n",
    "lr_l2_cm_2 = pd.DataFrame(lr_l2_cm_2, columns=lr_l2_SF.classes_, index=lr_l2_SF.classes_) #lr_l2_SF is instance of model\n",
    "lr_l2_cm_2\n",
    "\n",
    "\n",
    "logreg_cv1 = LogisticRegressionCV(Cs=20, solver='liblinear', cv=3, penalty='l1', scoring='f1')\n",
    "cv_model1 = logreg_cv1.fit(X_train1, y_train1)\n",
    "logreg1 = LogisticRegression(solver='liblinear')\n",
    "C_vals = [0.0001, 0.001, 0.01, 0.1, .15, .25, .275, .33, 0.5, .66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]\n",
    "penalties = ['l1','l2']\n",
    "\n",
    "gs1 = GridSearchCV(logreg1, {'penalty': penalties, 'C': C_vals}, verbose=False, cv=15)\n",
    "gs1.fit(X1, y1)\n",
    "\n",
    "gs1.best_params_\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9c9274ef-c9f5-4d56-b286-ecc8709eff9f"
   },
   "source": [
    "#### Rebuild this model with scikit-learn.\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy, AUC, precision and recall of the model. \n",
    "- Discuss the differences and explain when you want a high-recall or a high-precision model in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "8c22664b-92e4-4fc2-b7ac-fbac865845d3"
   },
   "source": [
    "#### Compare L1 and L2 regularization for this logistic regression model. What effect does this have on the coefficients learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "172fd952-5012-4630-81f4-1206da6eb820"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "56cc8854-d722-411d-a6c7-e86310710f67"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "fead9b5b-7316-405d-87fd-e144dff0cbeb"
   },
   "source": [
    "#### Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "12d5edeb-a272-43a0-9977-d951f12fedfb"
   },
   "source": [
    "#### Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary - which entries have the highest predicted salaries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate the logistic regression model using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "fec80936-37bc-4922-89bd-b5d615566c9c"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "d42b9fd8-39d5-416a-b40b-7410e6396c11"
   },
   "source": [
    "#### Re-test L1 and L2 regularization. You can use LogisticRegressionCV to find the optimal reguarlization parameters. \n",
    "- Re-test what text features are most valuable.  \n",
    "- How do L1 and L2 change the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "7570e237-c8cc-4e26-b569-7aee10627e79"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "e3a0c83d-e3b8-4bed-b864-7e795b34a3d4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
