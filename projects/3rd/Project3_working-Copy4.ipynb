{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "Once you've chosen your scenario, download the data from [the Iowa website](https://data.iowa.gov/Economy/Iowa-Liquor-Sales/m3tr-qhgy) in csv format. Start by loading the data with pandas. You may need to parse the date columns appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>Reportdata number 1</th>\n",
       "      <th>Reportdata link 1</th>\n",
       "      <th>Reportdata link 1_link</th>\n",
       "      <th>Reportdata number 2</th>\n",
       "      <th>Reportdata link 2</th>\n",
       "      <th>Reportdata link 2_link</th>\n",
       "      <th>Reportdata number 3</th>\n",
       "      <th>Reportdata number 4</th>\n",
       "      <th>Reportdata number 5</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://zipatlas.com/us/ia/zip-code-comparison/...</td>\n",
       "      <td>101</td>\n",
       "      <td>50009</td>\n",
       "      <td>http://zipatlas.com/us/ia/altoona/zip-50009.htm</td>\n",
       "      <td>41.640625, -93.458835</td>\n",
       "      <td>Altoona</td>\n",
       "      <td>http://zipatlas.com/us/ia/altoona.htm</td>\n",
       "      <td>12,008</td>\n",
       "      <td>406.63</td>\n",
       "      <td>#8,763</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://zipatlas.com/us/ia/zip-code-comparison/...</td>\n",
       "      <td>102</td>\n",
       "      <td>51451</td>\n",
       "      <td>http://zipatlas.com/us/ia/lanesboro/zip-51451.htm</td>\n",
       "      <td>42.184080, -94.695158</td>\n",
       "      <td>Lanesboro</td>\n",
       "      <td>http://zipatlas.com/us/ia/lanesboro.htm</td>\n",
       "      <td>148</td>\n",
       "      <td>401.19</td>\n",
       "      <td>#8,801</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://zipatlas.com/us/ia/zip-code-comparison/...</td>\n",
       "      <td>103</td>\n",
       "      <td>52002</td>\n",
       "      <td>http://zipatlas.com/us/ia/dubuque/zip-52002.htm</td>\n",
       "      <td>42.521344, -90.776310</td>\n",
       "      <td>Dubuque</td>\n",
       "      <td>http://zipatlas.com/us/ia/dubuque.htm</td>\n",
       "      <td>11,539</td>\n",
       "      <td>400.73</td>\n",
       "      <td>#8,806</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://zipatlas.com/us/ia/zip-code-comparison/...</td>\n",
       "      <td>104</td>\n",
       "      <td>50706</td>\n",
       "      <td>http://zipatlas.com/us/ia/waterloo/zip-50706.htm</td>\n",
       "      <td>42.408728, -92.258971</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>http://zipatlas.com/us/ia/waterloo.htm</td>\n",
       "      <td>1,035</td>\n",
       "      <td>395.19</td>\n",
       "      <td>#8,843</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://zipatlas.com/us/ia/zip-code-comparison/...</td>\n",
       "      <td>105</td>\n",
       "      <td>51355</td>\n",
       "      <td>http://zipatlas.com/us/ia/okoboji/zip-51355.htm</td>\n",
       "      <td>43.388189, -95.136678</td>\n",
       "      <td>Okoboji</td>\n",
       "      <td>http://zipatlas.com/us/ia/okoboji.htm</td>\n",
       "      <td>825</td>\n",
       "      <td>388.07</td>\n",
       "      <td>#8,902</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  Reportdata number 1  \\\n",
       "0  http://zipatlas.com/us/ia/zip-code-comparison/...                  101   \n",
       "1  http://zipatlas.com/us/ia/zip-code-comparison/...                  102   \n",
       "2  http://zipatlas.com/us/ia/zip-code-comparison/...                  103   \n",
       "3  http://zipatlas.com/us/ia/zip-code-comparison/...                  104   \n",
       "4  http://zipatlas.com/us/ia/zip-code-comparison/...                  105   \n",
       "\n",
       "   Reportdata link 1                             Reportdata link 1_link  \\\n",
       "0              50009    http://zipatlas.com/us/ia/altoona/zip-50009.htm   \n",
       "1              51451  http://zipatlas.com/us/ia/lanesboro/zip-51451.htm   \n",
       "2              52002    http://zipatlas.com/us/ia/dubuque/zip-52002.htm   \n",
       "3              50706   http://zipatlas.com/us/ia/waterloo/zip-50706.htm   \n",
       "4              51355    http://zipatlas.com/us/ia/okoboji/zip-51355.htm   \n",
       "\n",
       "     Reportdata number 2 Reportdata link 2  \\\n",
       "0  41.640625, -93.458835           Altoona   \n",
       "1  42.184080, -94.695158         Lanesboro   \n",
       "2  42.521344, -90.776310           Dubuque   \n",
       "3  42.408728, -92.258971          Waterloo   \n",
       "4  43.388189, -95.136678           Okoboji   \n",
       "\n",
       "                    Reportdata link 2_link Reportdata number 3  \\\n",
       "0    http://zipatlas.com/us/ia/altoona.htm              12,008   \n",
       "1  http://zipatlas.com/us/ia/lanesboro.htm                 148   \n",
       "2    http://zipatlas.com/us/ia/dubuque.htm              11,539   \n",
       "3   http://zipatlas.com/us/ia/waterloo.htm               1,035   \n",
       "4    http://zipatlas.com/us/ia/okoboji.htm                 825   \n",
       "\n",
       "  Reportdata number 4 Reportdata number 5  Unnamed: 10  \n",
       "0              406.63              #8,763          407  \n",
       "1              401.19              #8,801          401  \n",
       "2              400.73              #8,806          401  \n",
       "3              395.19              #8,843          395  \n",
       "4              388.07              #8,902          388  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "import os\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# iowa_data = pd.read_csv('/Users/HudsonCavanagh/Documents/Iowa_Liquor_Sales.csv') -- this is where need to update with full dataset (eventually)\n",
    "iowa_data = pd.read_csv('/Users/HudsonCavanagh/Documents/Iowa_Liquor_sales_sample_10pct.csv')\n",
    "ia = pd.DataFrame(iowa_data) \n",
    "ia.dropna(how='any', axis=0, inplace=True)\n",
    "ia['Date'] = pd.to_datetime(ia['Date'], infer_datetime_format=True)\n",
    "\n",
    "iowa_zip_data = pd.read_csv('/Users/HudsonCavanagh/dsi-projects/projects/3rd - IA Liquor/iowa_zip_pop.csv')\n",
    "ia_zip_pop = pd.DataFrame(iowa_zip_data) \n",
    "ia_zip_pop.dropna(how='any', axis=0, inplace=True)\n",
    "\n",
    "\n",
    "works = []\n",
    "issues = []\n",
    "    \n",
    "for val in g.index:\n",
    "    if '-' in val:\n",
    "        issues.append(val)\n",
    "    elif str(int(val)) == val:\n",
    "        works.append(val)\n",
    "    else:\n",
    "        issues.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean IA ZIP POP HERE\n",
    "\n",
    "# ia_zip_pop = ia_zip_pop.loc['Reportdata link 1', 'Reportdata number 2', 'Reportdata link 2', 'Reportdata number 4']\n",
    "##ORIGINAL VERSION:\n",
    "# ia_zip_pop = ia_zip_pop.iloc[:,(2,4,5,8)]\n",
    "# column_iazip = ['zip', 'lat_long', 'city', 'pop_dense_heads_sqm']\n",
    "\n",
    "#REVISED FOR MERGING\n",
    "\n",
    "\n",
    "ia_zip_pop = ia_zip_pop.iloc[:,(2,10)]\n",
    "column_iazip = ['zip', 'pop_dense_heads_sqm']\n",
    "ia_zip_pop.columns = column_iazip\n",
    "# ia_zip_pop.dropna(inplace=True)\n",
    "ia_zip_pop['zip'] = ia_zip_pop['zip'].apply(lambda x: str(x))\n",
    "ia_zip_pop['pop_dense_heads_sqm'] = ia_zip_pop['pop_dense_heads_sqm'].apply(lambda x: float(x)) \n",
    "#could not get the above to read commas in numbers over 1k with float or int, did conversion in google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269258"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns in main dataframe\n",
    "\n",
    "ia.rename(columns={'Date': 'date', 'Store Number': 'store_num', 'City': 'city', 'Zip Code': 'zip', 'County Number': 'county_num', 'County': 'county_name', 'Category': 'cat', 'Category Name': 'cat_name'}, inplace=True)\n",
    "ia.rename(columns={'Vendor Number': 'vend_id', 'Item Number': 'item_id', 'Item Description': 'item', 'Bottle Volume (ml)': 'vol_per_bottle_ml', 'State Bottle Cost': 'bottle_cost', 'State Bottle Retail': 'retail_unit_rev', 'Bottles Sold': 'bottles_sold'}, inplace=True)\n",
    "ia.rename(columns={'Sale (Dollars)': 'trans_revenue', 'Volume Sold (Liters)': 'vol_sold_liters'}, inplace=True)\n",
    "ia = ia.iloc[:,0:17]\n",
    "\n",
    "len(ia['store_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CONVERT DATATYPES, prepare g with index zip\n",
    "\n",
    "# ia['date'].value_counts  #dtype time 64\n",
    "# ia['store_num'].value_counts  #int, should be string\n",
    "ia['store_num'] = ia['store_num'].apply(lambda x: str(x))\n",
    "# ia['city'].value_counts #object, ok\n",
    "# ia['zip'].value_counts #object, ok\n",
    "# ia['county_num'].value_counts #float, should be object\n",
    "ia['county_num'] = ia['county_num'].apply(lambda x: str(x))\n",
    "# ia['county_name'].value_counts #object, ok\n",
    "# ia['cat'].value_counts #int, should be obj\n",
    "                                          \n",
    "ia['cat'] = ia['cat'].apply(lambda x: str(x))\n",
    "                                          \n",
    "                                 \n",
    "# ia['cat_name'].value_counts #str\n",
    "ia['vend_id'] = ia['vend_id'].apply(lambda x: str(x))\n",
    "ia['item_id'] = ia['item_id'].apply(lambda x: str(x))\n",
    "# ia['item'].value_counts #str\n",
    "ia['liters_per_bottle'] = (ia['vol_per_bottle_ml'].apply(lambda x: float(x)/1000))\n",
    "ia['bottles_sold'] = (ia['bottles_sold'].apply(lambda x: float(x)))\n",
    "\n",
    "##THIS DATA CLEAN, JUST NEED TO CONVERT DOLLAR COLUMNS\n",
    "\n",
    "ia['bottle_cost'] = ia['bottle_cost'].apply(lambda x: x.strip('$'))\n",
    "ia['bottle_cost'] = ia['bottle_cost'].apply(lambda x: float(x))\n",
    "\n",
    "ia['retail_unit_rev'] = ia['retail_unit_rev'].apply(lambda x: x.strip('$'))\n",
    "ia['retail_unit_rev'] = ia['retail_unit_rev'].apply(lambda x: float(x))\n",
    "\n",
    "ia['trans_revenue'] = ia['trans_revenue'].apply(lambda x: x.strip('$'))\n",
    "ia['trans_revenue'] = ia['trans_revenue'].apply(lambda x: float(x))\n",
    "\n",
    "ia['profit'] = ((ia['retail_unit_rev']-ia['bottle_cost'])*ia['bottles_sold'])\n",
    "ia['profit_per_L'] = (ia['profit']/ia['liters_per_bottle'])\n",
    "ia['profit_margin'] = (ia['profit']/ia['trans_revenue'])\n",
    "\n",
    "ia_pop = pd.merge(ia, ia_zip_pop, how='left', on='zip', sort=False)\n",
    "g = ia_pop.set_index('zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add calculated features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit\n",
    "\n",
    "# def zipper(values):\n",
    "#     works = []\n",
    "#     issues = []\n",
    "    \n",
    "#     for val in values:\n",
    "#         if '-' in val:\n",
    "#             issues.append(val)\n",
    "#         elif str(int(val)) == val:\n",
    "#             works.append(val)\n",
    "#         else:\n",
    "#             issues.append(val)\n",
    "#     return works, issues\n",
    "\n",
    "\n",
    "# works = []\n",
    "# issues = []\n",
    "    \n",
    "# for val in g.index:\n",
    "#     if '-' in val:\n",
    "#         issues.append(val)\n",
    "#     elif str(int(val)) == val:\n",
    "#         works.append(val)\n",
    "#     else:\n",
    "#         issues.append(val)\n",
    "        \n",
    "\n",
    "#WHY is this O^2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2330606c2679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'timeit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/HudsonCavanagh/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/HudsonCavanagh/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1359\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot index with multidimensional key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/HudsonCavanagh/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_validate_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/HudsonCavanagh/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;31m# TODO: don't check the entire key unless necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m                 raise KeyError(\"None of [%s] are in the [%s]\" %\n",
      "\u001b[0;32m/Users/HudsonCavanagh/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_indexer_for\u001b[0;34m(self, target, **kwargs)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/HudsonCavanagh/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_indexer_non_unique\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   1998\u001b[0m             \u001b[0mtgt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2000\u001b[0;31m         \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2001\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_indexer_non_unique (pandas/index.c:6458)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/HudsonCavanagh/anaconda/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mresize\u001b[0;34m(a, new_shape)\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0mextra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNa\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_copies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mextra\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "g = g.loc[works]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#WORKING SPLITTING CELL\n",
    "\n",
    "g['year'] = g.date.dt.year\n",
    "g['quarters'] = g.date.dt.quarter\n",
    "g_2015 = g[g.year == 2015]\n",
    "q1 = g_2015[g_2015.quarters == 1]\n",
    "q2 = g_2015[g_2015.quarters == 2]\n",
    "q3 = g_2015[g_2015.quarters == 3]\n",
    "q4 = g_2015[g_2015.quarters == 4]\n",
    "q234 = g_2015[g_2015.quarters == [2 or 3 or 4]]\n",
    "q5 = g[g.year == 2016]\n",
    "\n",
    "\n",
    "q1_X = q1.drop('trans_revenue', 1)\n",
    "q1_X['constant'] = 1\n",
    "\n",
    "#COULD ADD BACK CAT, VEND categoricals\n",
    "q1_X = q1_X[['vol_sold_liters', 'profit', 'profit_per_L', 'profit_margin','pop_dense_heads_sqm', 'constant']]\n",
    "q234_y = q234['trans_revenue']\n",
    "q234_Y = pd.DataFrame(q234_y)\n",
    "\n",
    "# q1_X_trim = pd.merge(q1_X, q234_Y, how='left', left_index=1, right_index=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(q1_X, q234_Y, test_size=.33)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(q1_X_trim, q234_Y, test_size=.33) #with trim\n",
    "\n",
    "\n",
    "print \"       X Shape  Y Shape\"\n",
    "print \"Train\", X_train.shape, y_train.shape\n",
    "print \"Test \", X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data\n",
    "\n",
    "Perform some exploratory statistical analysis and make some plots, such as histograms of transaction totals, bottles sold, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record your findings\n",
    "\n",
    "Be sure to write out anything observations from your exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine the data\n",
    "Now you are ready to compute the variables you will use for your regression from the data. For example, you may want to\n",
    "compute total sales per store from Jan to March of 2015, mean price per bottle, etc. Refer to the readme for more ideas appropriate to your scenario.\n",
    "\n",
    "Pandas is your friend for this task. Take a look at the operations [here](http://pandas.pydata.org/pandas-docs/stable/groupby.html) for ideas on how to make the best use of pandas and feel free to search for blog and Stack Overflow posts to help you group data by certain variables and compute sums, means, etc. You may find it useful to create a new data frame to house this summary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine the data\n",
    "Look for any statistical relationships, correlations, or other relevant properties of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAKE TONS OF PLOTS, seaborn\n",
    "\n",
    "sns.JointGrid(\"pop_dense\", \"vol_sold_L\", data=q1)\n",
    "sns.JointGrid(\"pop_dense\", \"profit\", data=q1)\n",
    "sns.JointGrid(\"pop_dense\", \"profit_margin\", data=q1)\n",
    "sns.JointGrid(\"pop_dense\", \"vol_sold_L\", data=q1)\n",
    "\n",
    "\n",
    "#can do some more using this data:\n",
    "q1 q234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your models\n",
    "\n",
    "Using scikit-learn or statsmodels, build the necessary models for your scenario. Evaluate model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rcv = linear_model.RidgeCV(alphas=\n",
    "                           (.001, .001, .01, .1, .5, 1, 5, 10),\n",
    "                           store_cv_values=True)\n",
    "rcv_model = rcv.fit(X_train, y_train)\n",
    "y_predicted = rcv_model.predict(X_test)\n",
    "rcv_r2 =  r2_score(y_true=y_test, y_pred=y_predicted)\n",
    "rcv_r2\n",
    "\n",
    "plt.scatter(y_test, y_predicted) #compare the hold-out observed y values to the predictions (made with model from test data)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "\n",
    "print \"Score:\", rcv_model.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rcv_model.cv_values_.mean()\n",
    "\n",
    "rcv_model.alpha_ #this returns optimal alpha for dataset\n",
    "\n",
    "cross_val_score(lr, X, y, n_jobs=1, cv=5).mean() #multiple jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import linear_model\n",
    "\n",
    "\n",
    "# lm = linear_model.LinearRegression()\n",
    "\n",
    "# X = \n",
    "# y = \n",
    "\n",
    "# model = lm.fit(X, y)\n",
    "# predictions = lm.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # How is it performing? Plot the model's predictions against actual values\n",
    "# # s = s: size in points, c = color, zorder = layer order\n",
    "\n",
    "# plt.figure(figsize=(16,8))\n",
    "# plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "# plt.xlabel(\"Predicted Values\")\n",
    "# plt.ylabel(\"Actual Values\")\n",
    "# plt.show()\n",
    "# print \"MSE:\", mean_squared_error(y, predictions)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(lr, X, y, n_jobs=1, cv=5).mean() #multiple jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the residuals\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(y, y - predictions, c = 'b', marker = '+') # Look directly at the residuals\n",
    "plt.axhline(0, color='r') #from http://localhost:8888/notebooks/week03/W3%20L1.3_scikit-modeling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OLS\n",
    "\n",
    "# Note the difference in argument order\n",
    "OLSmodel = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Plot the model\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Actual Values\")\n",
    "plt.show()\n",
    "print \"MSE:\", mean_squared_error(y, predictions)\n",
    "\n",
    "cross_val_score(lr, X, y, n_jobs=1, cv=5).mean() #multiple jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(OLSmodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#standardized Ridge Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#standardized lasso model\n",
    "\n",
    "lcv = linear_model.LassoCV()\n",
    "lcv_model = lcv.fit(X_train, y_train)\n",
    "y_lasso_predicted = lcv_model.predict(X_test)\n",
    "lcv_r2 =  r2_score(y_true=y_test, y_pred=y_predicted)\n",
    "lcv_r2\n",
    "\n",
    "plt.scatter(y_test, y_lasso_predicted) #compare the hold-out observed y values to the predictions (made with model from test data)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Lasso Predictions\")\n",
    "\n",
    "print \"Score:\", lcv_model.score(X_test, y_test)\n",
    "\n",
    "print(lcv_model.alpha_, #this returns optimal alpha for dataset\n",
    "abs(lcv_model.coef_))\n",
    "\n",
    "final_predicts = ia.predict(modelname, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#iterate through r2 or mse a bunch\n",
    "\n",
    "for i in range(1000):\n",
    "    cross_val_list = []\n",
    "    n = cross_val_score(lasso, X, y, n_jobs=1, cv=5, scoring='r2').mean()\n",
    "    cross_val_list.append(n)\n",
    "print(np.mean(cross_val_list))\n",
    "\n",
    "\n",
    "# cross_val_score(lr, X, y, n_jobs=1, cv=5,\n",
    "#                 scoring='mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample code for cross_validated output\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dd, dy, test_size=.4)\n",
    "\n",
    "lcv_model = lcv.fit(X_train, y_train)\n",
    "lcv_pred = lcv.predict(X_test)\n",
    "lasso_r2 =  r2_score(y_true=y_test, y_pred=lcv_pred)\n",
    "print(\"R sq for Lasso Reg is:\", lasso_r2)\n",
    "\n",
    "print(\"cross validated r^2:\", np.mean(cross_val_score(lcv_model, X_test, y_test, scoring='r2', cv=5)))\n",
    "print(\"r^2 w/o cross-validation\", (lcv_model.score(X_test,y_test)))\n",
    "print(\"cross validated MSE (sign flipped):\", -np.mean(cross_val_score(lcv_model, X_test, y_test, scoring='mean_squared_error', cv=5)))\n",
    "print(\"MSE w/o cross-validation\", (lcv_model.score(X_test,y_test)))\n",
    "\n",
    "# mse\n",
    "# bar\n",
    "# bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###LOSS FUNCTIONS\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "print \"RMSE:\", mean_squared_error(ys, predictions)\n",
    "print \"MAE:\", mean_absolute_error(ys, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#QUANT REG\n",
    "\n",
    "df = pd.DataFrame(np.array([xs, ys]).transpose(), columns=[\"x\", \"y\"])\n",
    "df.columns = [\"x\", \"y\"]\n",
    "mod = smf.quantreg('y ~ x', df)\n",
    "res = mod.fit(q=.5)\n",
    "print(res.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HELPFUL FUNCTIONS\n",
    "\n",
    "# Gradient Descent/ Optimizing Functions:\n",
    "    \n",
    "    \n",
    "def mean_squared_error(y_true, x, beta0, beta1):\n",
    "    y_pred = beta0 + x * beta1\n",
    "    mean_sq_err = np.mean((y_true - y_pred)**2)\n",
    "    return mean_sq_err\n",
    "\n",
    "def gradient_update(y, x, beta0, beta1, step_size):\n",
    "    \n",
    "    beta0_gradient = 0\n",
    "    beta1_gradient = 0\n",
    "    \n",
    "    N = float(len(y))\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        \n",
    "        # add to the beta0 gradient for each x,y using the partial derivative with respect to beta0\n",
    "        beta0_gradient += (2./N * -1 * (y[i] - (beta0 + beta1*x[i])))\n",
    "        \n",
    "        # add to the beta1 gradient for each x,y using the partial derivative with respect to beta1\n",
    "        beta1_gradient += (2./N * -1 * x[i] * (y[i] - (beta0 + beta1*x[i])))\n",
    "        \n",
    "    # update beta0 and beta1:\n",
    "    beta0 = beta0 - (step_size * beta0_gradient) #subtracting because we want to move in the opposite direction of the gradient\n",
    "    #this is because we want to minimize function\n",
    "    beta1 = beta1 - (step_size * beta1_gradient)\n",
    "    \n",
    "    return [beta0, beta1]\n",
    "\n",
    "\n",
    "\n",
    "def gradient_descent_iterator(y, x, beta0, beta1, step_size=.0001, iterations=500):\n",
    "    \n",
    "    mean_squared_errors = []\n",
    "    mean_squared_errors.append(mean_squared_error(y, x, beta0, beta1))\n",
    "    \n",
    "    beta0s = [beta0]\n",
    "    beta1s = [beta1]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        [beta0, beta1] = gradient_update(y, x, beta0, beta1, step_size)\n",
    "        mean_squared_errors.append(mean_squared_error(y, x, beta0, beta1))\n",
    "        beta0s.append(beta0)\n",
    "        beta1s.append(beta1)\n",
    "        \n",
    "    return [mean_squared_errors, beta0s, beta1s]\n",
    "\n",
    "\n",
    "\n",
    "# format for runnning the above 3 functions:\n",
    "    \n",
    "x = np.random.random_sample(100)*100\n",
    "y = x + np.random.normal(np.random.normal(0,15), 30, size=100) + 100\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.scatter(x, y, s=70, c='steelblue')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "### Plotting functions from earlier (nonessential)\n",
    "\n",
    "\n",
    "\n",
    "def plot_regression(x, y, model):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    axes = plt.gca()\n",
    "    \n",
    "    intercept = model.params[0]\n",
    "    slope = model.params[1]\n",
    "\n",
    "    for x_, y_ in zip(x, y):    \n",
    "        plt.plot((x_, x_), (y_, x_*slope + intercept),\n",
    "                 'k-', ls='dashed', lw=1)\n",
    "        \n",
    "    plt.scatter(x, y, s=70, c='steelblue')\n",
    "    \n",
    "    x_points = np.linspace(axes.get_xlim()[0], axes.get_xlim()[1], 100)\n",
    "    \n",
    "    regline_x = x_points\n",
    "    regline_y = x_points*slope + intercept\n",
    "\n",
    "    plt.plot(regline_x, regline_y, c='darkred', lw=3.5)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_leastsq_loss(model):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    \n",
    "    resids = model.resid\n",
    "    \n",
    "    resid_lim = np.max([abs(np.min(resids)), abs(np.max(resids))]) + 1\n",
    "    \n",
    "    resid_points = np.linspace(-1*resid_lim, resid_lim, 200)\n",
    "    \n",
    "    for r in resids:\n",
    "        plt.plot((r, r), (0, r**2), 'k-', ls='dashed', lw=2)\n",
    "        \n",
    "    plt.plot(resid_points, resid_points**2, c='gold', alpha=0.7)\n",
    "    \n",
    "\n",
    "def plot_residuals_ladloss(model):\n",
    "    \n",
    "    resids = model.resid\n",
    "    \n",
    "    resid_lim = np.max([abs(np.min(resids)), abs(np.max(resids))]) + 1\n",
    "    \n",
    "    resid_points = np.linspace(-1*resid_lim, resid_lim, 200)\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    \n",
    "    for r in resids:\n",
    "        \n",
    "        plt.plot((r, r), (0, abs(r)), 'k-', ls='dashed', lw=1)\n",
    "        \n",
    "    plt.plot(resid_points, np.abs(resid_points), c='gold', alpha=0.7)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "##REMINDER OF NEXT STEPS:\n",
    "#from http://localhost:8888/notebooks/week03/loss-functions-regression-metrics-practice.ipynb\n",
    "# 4: Choose a continuous response variable and predictor variable from the dataset\n",
    "# 5: Choose a small subset of the predictor and response variables you chose\n",
    "# 6. Build a least squares regression model predicting your response from your predictors\n",
    "plot_regression(x, y, model)\n",
    "7. Plot the least squares regression\n",
    "8. Build a least absolute deviation quantreg model on the same sample\n",
    "Plot the LAD regression\n",
    "\n",
    "10. Calculate the RMSE and the MAE between you response and predicted response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUll run-through of gradient descent iteration (redundant with some code above):\n",
    "    \n",
    "def func(x):    #this needs to be modified to whatever the specific function is\n",
    "    if x <= 1:\n",
    "        return 2 * x * x\n",
    "    return 2\n",
    "\n",
    "def gradient(x): #this needs to be the derivative of the func\n",
    "    if x <= 1:\n",
    "        return 4 * x\n",
    "    return 0\n",
    "\n",
    "def gradient_descent(x, l=0.1):\n",
    "    vector = np.array(x)\n",
    "    return vector - l * np.array(gradient(x))\n",
    "\n",
    "\n",
    "def iterate(x0, n=10):\n",
    "    xs = [x0]\n",
    "    ys = [func(x0)]\n",
    "    for i in range(n):\n",
    "        x = gradient_descent(xs[-1], l=0.1)\n",
    "        xs.append(x)\n",
    "        ys.append(func(x))\n",
    "    return xs, ys    \n",
    "\n",
    "\n",
    "xs = np.arange(-2, 3, 0.1)\n",
    "ys = map(func, xs)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(xs, ys, alpha=0.5, ls='dashed')\n",
    "\n",
    "# Start gradient descent at x = -1.5\n",
    "xs2, ys2 = iterate(-1.5, n=100)\n",
    "plt.scatter(xs2, ys2, c='r', s=100)\n",
    "\n",
    "# Start gradient descent at x = 2; where does it go?\n",
    "xs2, ys2 = iterate(2, n=100)\n",
    "plt.scatter(xs2, ys2, c='y', s=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot your results\n",
    "\n",
    "Again make sure that you record any valuable information. For example, in the tax scenario, did you find the sales from the first three months of the year to be a good predictor of the total sales for the year? Plot the predictions versus the true values and discuss the successes and limitations of your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the data and the best fit line\n",
    "## The data\n",
    "plt.scatter(X, y)\n",
    "## The line / model\n",
    "plt.plot(X, predictions)\n",
    "\n",
    "plt.show()\n",
    "print \"r^2:\", model.score(X, y)\n",
    "print \"RMSE:\", mean_squared_error(ys, predictions)\n",
    "print \"MAE:\", mean_absolute_error(ys, predictions)\n",
    "print \"Coefficients:\", model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Present the Results\n",
    "\n",
    "Present your conclusions and results. If you have more than one interesting model feel free to include more than one along with a discussion. Use your work in this notebook to prepare your write-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
